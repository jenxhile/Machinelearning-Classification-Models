# -*- coding: utf-8 -*-
"""Tehtävä3_osa1_Luokittelumallit_JennaHilden.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ktwAP5ECnTRKA-T36-qdMQnEZPhTQdMc

# Tehtävä 3 osa 1: Luokittelumallit

Pyrin ennustamaan viinin rypälelakkeen sen muiden ominaisuuksien avulla käyttäen kahta eri luokittelumallia. Arvioin ensin mallien suoriutumista keskenään, jonka jälkeen jatkan analyysiä kahdella valitsemallani mallilla.
Datana käytetään tiedostoa wine.xlsx (lähde: https://archive.ics.uci.edu/ml/datasets/Wine).

## Valmistelevat toimet
"""

# yhdistetään Google Driveen
from google.colab import drive
drive.mount('/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# valitaan työskentelykansio
# %cd /gdrive/MyDrive/data

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# train_test_split osaa jakaa datan opetusdataan ja testidataan
from sklearn.model_selection import train_test_split

# Käytettävät mallit
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

# Sekaannusmatriisin näyttämiseen
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

"""## Aineiston tuonti ja dataan tutustuminen"""

df = pd.read_excel('wine.xlsx')
df.head()

# Tarkistetaan rivien ja sarakkeiden lukumäärä
df.shape

# Tarkastellaan muuttujien sisältämiä tietoja tarkemmin
df.info()

"""Ei puuttuvia arvoja ja kaikki luvut ovat numeerisia. Datassa on 14 saraketta, joista X1-X13 edustavat viinin kemiallisia ja fysikaalisia ominaisuuksia: Alcohol, Malic Acid, Ash, Alcalinity Of Ash, Magnesium, Total Phenols, Flavanoids, Nonflavanoid Phenols, Proanthocyanins, Color Intensity, Hue, OD280/OD315 Of Diluted Wines, Proline) (Lähde: https://archive.ics.uci.edu/dataset/109/wine)"""

# tilastolliset tunnusluvut
df.describe().round(2)

# minkä verran eri rypälelajikkeita on?
pd.crosstab(df['Y'], 'f')

"""Rypälelajikkeita on 3 erilaista. Data on suhteellisen tasaisesti jakautunut, joten sitä ei tarvitse tasapainottaa.

## Aineiston muokkaaminen ja tarkastelu
"""

# muutetaan sarakeotsikot kuvaavammiksi
df.columns = ['Rypälelajike','Alkoholi', 'Omenahappo', 'Tuhka', 'Tuhkan Alkaliniteetti', 'Magnesium', 'Yhteensä Fenoleja', 'Flavonoidit', 'Ei-flavonoidiset Fenolit', 'Proantosyaniinit', 'Värin Intensiteetti', 'Sävy', 'OD280/OD315 Laimennetuista Viineistä', 'Proliini']

# korrelaatiot
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr().round(2), annot=True)

"""Muuttujissa on paljon negatiivista ja positiivista korrelaatiota kohdemuuttujan kanssa. Tarkastellaan seuraavaksi, mitkä niistä ovat merkitseviä.

# Tarkastellaan, mitkä muuttujat ovat merkitseviä
"""

# selittävät muuttujat (dataframe)
X = df.drop(columns=['Rypälelajike'])

# kohdemuuttuja (series)
y = df['Rypälelajike']

# tuodaan Statsmodels-kirjasto tilastollisten mallien rakentamista varten
import statsmodels.api as sm

# lisätään vakiotermi selittävien muuttujien matriisiin X
# tämä mahdollistaa mallin laskemisen, joka sisältää perusvaihtelun
X = sm.add_constant(X)
# Luodaan ja sovitetaan lineaarinen regressiomalli (OLS) dataan
# y on selitettävä muuttuja ja X on selittävien muuttujien matriisi
malli_sm = sm.OLS(y, X).fit()
# Tulostetaan mallin yhteenveto
# Sisältää kertoimien estimoinnit, p-arvot, R^2-arvon ja muut mallin tilastolliset tunnusluvut
print(malli_sm.summary())

"""On hyvä jos p-arvot (sarake P>|t|) ovat pienempiä kuin 0.05. Tästä syystä voidaan todeta, että muuttujat Omenahappo, Tuhka, Magnesium, Ei-flavonoidiset Fenolit, Proantosyaniinit ja Sävy voidaan tiputtaa pois."""

# Haetaan p-arvot mallista
p_arvot = malli_sm.pvalues

# Näytetään muuttujat, joiden p-arvo on alle 0.05 (poistetaan vakiotermi 'const')
merkitsevat = p_arvot[p_arvot < 0.05].index.tolist()
if 'const' in merkitsevat:
    merkitsevat.remove('const')

print("Tilastollisesti merkitsevät muuttujat (p < 0.05):")
print(merkitsevat)

# Luodaan uusi dataframe vain merkitsevistä muuttujista
X_filtered = X[merkitsevat]

print("\nPoistetut muuttujat:")
print(list(set(X.columns) - set(merkitsevat) - {'const'}))

# määritellään selittävät muuttujat uudelleen
X = df[merkitsevat]
X.head()

# Miten hyvin lajike erottuu merkitsevien muuttujien kesken?
sns.pairplot(df[merkitsevat + ['Rypälelajike']], hue='Rypälelajike')

"""Klusteroituminen on selkeästi havaittavissa. Tämä viittaa siihen, että eri rypälelajikkeet voivat muodostaa selkeästi erottuvia ryhmiä, mikä on hyvä merkki luokittelumallin rakentamista varten.

# Datan jakaminen opetus- ja testidataan
"""

# jako opetus- ja testidataan
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)

X_train.shape

X_test.shape

"""Oletuksena train_test_split jakaa datan 75 % opetukseen ja 25 % testaukseen.

## Mallien sovitus
Testaan ensin mallin sovitusta kaikkiin malleihin, jonka jälkeen valitsen kaksi mallia, joiden kanssa jatkan analyysiä.
"""

# logistinen regressio
lrc = LogisticRegression(random_state=2)
lrc.fit(X_train, y_train)

# päätöspuu
dtc = DecisionTreeClassifier(max_depth=3, random_state=2)
dtc.fit(X_train, y_train)

# satunnaismetsä
rfc = RandomForestClassifier(max_depth=3, random_state=2)
rfc.fit(X_train, y_train)

# gradienttitehostus
gbc = GradientBoostingClassifier(max_depth=3, random_state=2)
gbc.fit(X_train, y_train)

"""## Mallien arviointia"""

print('Ennusteiden tarkkuus opetusdatassa:')
print(f'Logistinen regressio {lrc.score(X_train, y_train):.4f}')
print(f'Päätöspuu {dtc.score(X_train, y_train):.4f}')
print(f'Satunnaismetsä {rfc.score(X_train, y_train):.4f}')
print(f'Gradienttitehostus {gbc.score(X_train, y_train):.4f}')

print('Ennusteiden tarkkuus testidatassa:')
print(f'Logistinen regressio {lrc.score(X_test, y_test):.4f}')
print(f'Päätöspuu {dtc.score(X_test, y_test):.4f}')
print(f'Satunnaismetsä {rfc.score(X_test, y_test):.4f}')
print(f'Gradienttitehostus {gbc.score(X_test, y_test):.4f}')

"""Valitsen kaksi mallia tarkempaan analyysiin:

Päätöspuu:

Paras suorituskyky testidatassa (0.9556)
Hyvä tasapaino opetus- (0.9925) ja testidatan (0.9556) välillä
Yksinkertaisempi tulkita kuin muut mallit
Ei osoita vakavaa ylisovittamista


Satunnaismetsä:


Yhtä hyvä suorituskyky testidatassa kuin päätöspuulla (0.9556)
Sama tasapaino opetus- (0.9925) ja testidatan välillä
Yleensä vakaampi ennustuksissa kuin yksittäinen päätöspuu
Antaa todennäköisyysarviot eri luokille

En valitse seuraavia:

* Gradienttitehostusta, koska se osoittaa selvää ylisovittamista (1.0000 → 0.9333)
* Logistista regressiota, koska sen suorituskyky on heikompi sekä opetus- (0.9624) että testidatassa (0.9111)

"""

# havainnollistetaan päätöspuuta
plt.figure(figsize=(14,8))
plot_tree(decision_tree=dtc,
          feature_names=['Alkoholi', 'Tuhkan Alkaliniteetti', 'Yhteensä Fenoleja', 'Flavonoidit', 'Värin Intensiteetti', 'OD280/OD315 Laimennetuista Viineistä', 'Proliini'])
plt.show()

"""Useimmat lehtisolmut saavuttavat täydellisen puhtauden (gini = 0.0).
Malli pääsee puhtaisiin luokitteluihin vain muutamalla jaolla.
Juurisolmun korkeasta epäpuhtaudesta (gini = 0.65) päästään nopeasti puhtaampiin jakoihin.

## Opetusdatan arviointi
"""

# lasketaan ennusteet opetusdatalle sekaannusmatriisin tekemistä varten
y_train_rfc = rfc.predict(X_train)
y_train_dtc = dtc.predict(X_train)

# Lasketaan sekaannusmatriisit
cm_rfc = confusion_matrix(y_train, y_train_rfc)
cm_dtc = confusion_matrix(y_train, y_train_dtc)

# Luodaan kuvapohja, jossa on kaksi rinnakkaista sekaannusmatriisia
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Satunnaismetsän sekaannusmatriisi
ConfusionMatrixDisplay(confusion_matrix=cm_rfc).plot(ax=axes[0])
axes[0].set_title("Satunnaismetsä, opetusdata")
axes[0].set_xlabel('Ennuste')
axes[0].set_ylabel('Toteutunut')

# Päätöspuun sekaannusmatriisi
ConfusionMatrixDisplay(confusion_matrix=cm_dtc).plot(ax=axes[1])
axes[1].set_title("Päätöspuu, opetusdata")
axes[1].set_xlabel('Ennuste')
axes[1].set_ylabel('Toteutunut')

# Näytetään kuvaajat
plt.tight_layout()
plt.show()

"""Satunnaismetsä

Erittäin hyvä tarkkuus: 40 + 57 + 35 = 132 oikeaa ennustetta.
Vain 1 väärä luokitus.


Päätöspuu

Sama tulos: 39 + 58 + 35 = 132 oikeaa ennustetta.
Vain 1 väärä luokitus.


Molemmat mallit suoriutuvat yhtä hyvin, mutta ne tekevät virheen eri kohdassa.

## Testidatan arviointi
"""

# lasketaan ennusteet testidatalle sekaannusmatriisin tekemistä varten
y_test_rfc = rfc.predict(X_test)
y_test_dtc = dtc.predict(X_test)

# Lasketaan sekaannusmatriisit
cm_rfc = confusion_matrix(y_test, y_test_rfc)
cm_dtc = confusion_matrix(y_test, y_test_dtc)

# Luodaan kuvapohja
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# satunnaismetsän sekaannusmatriisi
ConfusionMatrixDisplay(confusion_matrix=cm_rfc).plot(ax=axes[0])
axes[0].set_title("Satunnaismetsä, testidata")
axes[0].set_xlabel('Ennuste')
axes[0].set_ylabel('Toteutunut')

# Decision Tree sekaannusmatriisi
ConfusionMatrixDisplay(confusion_matrix=cm_dtc).plot(ax=axes[1])
axes[1].set_title("Decision Tree, testidata")
axes[1].set_xlabel('Ennuste')
axes[1].set_ylabel('Toteutunut')

plt.tight_layout()
plt.show()

"""Havainnot testidatan sekaannusmatriiseista:

Suorituskyky on hieman heikentynyt (opetusdatassa vain 1 virhe, testidatassa 2 virhettä)
Tämä on normaalia ja kertoo, että mallit eivät merkittävästi ylisovita.
Virheiden johdonmukaisuus (molemmat mallit tekevät samat virheet) viittaa siihen, että nämä näytteet ovat todennäköisesti erityisen haastavia luokitella.

Satunnaismetsä

Oikeat ennusteet: 17 + 13 + 13 = 43 oikeaa ennustetta.
2 väärää ennustetta.
Eniten vaikeuksia luokan 0 ennustamisessa (2 väärää luokitusta).


Päätöspuu

Oikeat ennusteet: 17 + 13 + 13 = 43 oikeaa ennustetta
2 väärää ennustetta.
Eniten vaikeuksia luokan 0 ennustamisessa (2 väärää luokitusta).

## Ennustaminen
"""

# datan luominen kahdelle uudelle viinille
X_uudet = pd.DataFrame({
    'Alkoholi': [13.5, 14.1],
    'Tuhkan Alkaliniteetti': [18.9, 16.5],
    'Yhteensä Fenoleja': [2.8, 3.1],
    'Flavonoidit': [2.5, 3.0],
    'Värin Intensiteetti': [5.0, 6.5],
    'OD280/OD315 Laimennetuista Viineistä': [3.0, 2.8],
    'Proliini': [800, 1100]
})
X_uudet

# lasketaan ennusteet
# satunnaismetsä
ennuste_rfc = rfc.predict(X_uudet)

# päätöspuu
ennuste_dtc = dtc.predict(X_uudet)

# lasketaan todennäköisyydet
todnak_rfc = rfc.predict_proba(X_uudet).round(2)
todnak_dtc = dtc.predict_proba(X_uudet).round(2)

# ennusteet dataframeen
X_ennuste = X_uudet.copy()
X_ennuste['ennuste rfc'] = ennuste_rfc
X_ennuste['ennuste dtc'] = ennuste_dtc

# satunnaismetsän todennäköisyydet taulukkoon
X_ennuste['todennäköisyys rfc, luokka 1'] = todnak_rfc[:, 0]
X_ennuste['todennäköisyys rfc, luokka 2'] = todnak_rfc[:, 1]
X_ennuste['todennäköisyys rfc, luokka 3'] = todnak_rfc[:, 2]
# päätöspuun todennäköisyydet taulukkoon
X_ennuste['todennäköisyys dtc, luokka 1'] = todnak_dtc[:, 0]
X_ennuste['todennäköisyys dtc, luokka 2'] = todnak_dtc[:, 1]
X_ennuste['todennäköisyys dtc, luokka 3'] = todnak_dtc[:, 2]

X_ennuste

"""Molemmat mallit ennustavat kummankin viinin kuuluvan luokkaan 1.
Mallien varmuus ennusteissa kuitenkin eroaa:

Satunnaismetsä (rfc) on epävarma ennusteistaan:

Ensimmäiselle viinille se ennustaa:

* 80% todennäköisyys luokalle 1
* 16% todennäköisyys luokalle 2
* 4% todennäköisyys luokalle 3


Toiselle viinille:

* 96% todennäköisyys luokalle 1
* 4% todennäköisyys luokalle 2
* 0% todennäköisyys luokalle 3

Päätöspuu (dtc) on täysin varma ennusteestaan:
* Todennäköisyys 100% luokalle 1 molemmissa viineissä
* Antaa 0% todennäköisyyden muille luokille (2 ja 3)




Satunnismetsä antaa realistisemman kuvan ennusteen epävarmuudesta, kun taas päätöspuu on ehkä liiankin varma ennusteistaan. Tämä on tyypillistä näille malleille - ensemble-menetelmät kuten satunnaismetsä tuottavat yleensä maltillisempia todennäköisyysarvioita kuin yksittäiset päätöspuut.
Vaikka molemmat mallit päätyvät samaan lopputulokseen, satunnaismetsän tapa ilmaista epävarmuutta tekee siitä luotettavamman vaihtoehdon käytännön sovelluksissa.
"""